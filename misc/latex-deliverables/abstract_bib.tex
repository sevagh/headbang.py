\documentclass[letter,12pt]{report}
%\setlength{\parindent}{0pt}
\usepackage[left=2cm, right=2cm, top=2cm, bottom=2cm]{geometry}
\usepackage[shortlabels]{enumitem}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{verbatim}
\usepackage{listings}
\usepackage{minted}
\usepackage{subfig}
\usepackage{titling}
\usepackage{caption}
\setlength{\droptitle}{1cm}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}
\usepackage{setspace}
\renewcommand{\topfraction}{0.85}
\renewcommand{\textfraction}{0.1}
\renewcommand{\floatpagefraction}{0.75}
\usepackage[backend=biber,authordate]{biblatex-chicago}
\addbibresource{citations.bib}
\usepackage{titlesec}
 
\titleformat{\chapter}[display]
  {\normalfont\bfseries}{}{0pt}{\Huge}

\begin{document}

\noindent\Large{\textbf{headbang.py}}\\
\large{Final project abstract. MUMT 621, April 13, 2021}\\
\large{Sevag Hanssian, 260398537}

\noindent\hrulefill

\vspace{2em}

headbang.py is a Python library and collection of command-line tools exploring two aspects of MIR beat tracking:

\begin{enumerate}
	\item
		Audio beat tracking which considered the outputs of 6 separate beat tracking algorithms in a consensus, and aligned the result with strong percussive onsets in progressive metal music. The goal was to locate sparse, strong beats where a human may headbang due to the psychological phenomenon of groove (\cite{groove}). The testing was performed mostly manually and several examples were shown in the demo website. A recreation of a MIREX beat tracking evaluation on the SMC dataset (\cite{smcdataset}) was done on different combinations of consensus, and a few showed improved Goto scores over the top-performing reference algorithm. Finally, a visual animation tool was created to compare the outputs of the different beat trackers side-by-side as a debugging aid. One potential application for the presented beat tracking algorithm is to drive an automated light show at a metal concert, where the sparsity of the predictions is appropriate for reducing visual fatigue. 
	\item
		Headbanging motion analysis of human subjects in metal musical videos from YouTube (e.g., concert footage, or clips of musicians playing instruments). The OpenPose 2D pose estimation library (\cite{openpose}) was used to analyze peaks in the vertical motion of the head and face, to track headbanging motion and tempo alongside audio beat and tempo tracking analysis. Two experimental ideas were presented as additional arguments to the script, including supplementing audio beat tracking with motion-detected beat annotations, and detection of strong agreement on the beat in songs where multiple subjects are headbanging in unison.
\end{enumerate}

The source code of headbang.py is available,\footnote{\url{https://github.com/sevagh/headbang.py}} and there is also a website\footnote{\url{https://sevagh.github.io/headbang.py}} with design documents, diagrams, and audio and video sample outputs.

\vfill
\clearpage

\nocite{*}
\printbibheading[title={\vspace{-3.5em}References},heading=bibnumbered]
\vspace{-1.5em}
\printbibliography[heading=none]

\end{document}
